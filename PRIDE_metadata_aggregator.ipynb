{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUDPjiiB56pYUMn0FjlbuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e75699f323a1409091dcdb99f0a104dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f46a07c6969340adbaa8bed1fed5ac05",
              "IPY_MODEL_90893764148049f586a4a4d747c73c22",
              "IPY_MODEL_096cee408880456e91c49592ab98e5e8"
            ],
            "layout": "IPY_MODEL_de339ba7e798423c91421b4dfe2619ac"
          }
        },
        "f46a07c6969340adbaa8bed1fed5ac05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45e19239ac84a1f8094cfd39c158d9e",
            "placeholder": "​",
            "style": "IPY_MODEL_9c422c2dfb6d4c89a4cc317d68af8636",
            "value": "Processing metadata files: 100%"
          }
        },
        "90893764148049f586a4a4d747c73c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552c802433484fb0854afef8c2baafa8",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cbde74e877c4c9b8ccb38a3ce233296",
            "value": 8
          }
        },
        "096cee408880456e91c49592ab98e5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_385121cef0c74f149e915b86dcb21a48",
            "placeholder": "​",
            "style": "IPY_MODEL_bfafcc5b1bbb4ba0be87779b699227bd",
            "value": " 8/8 [00:00&lt;00:00, 123.18it/s]"
          }
        },
        "de339ba7e798423c91421b4dfe2619ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45e19239ac84a1f8094cfd39c158d9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c422c2dfb6d4c89a4cc317d68af8636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "552c802433484fb0854afef8c2baafa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cbde74e877c4c9b8ccb38a3ce233296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "385121cef0c74f149e915b86dcb21a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfafcc5b1bbb4ba0be87779b699227bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palaeoprot/PRIDE/blob/main/PRIDE_metadata_aggregator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRIDE Metadata Aggregator\n",
        "\n",
        "## Overview\n",
        "This script aggregates metadata from multiple PRIDE (PRoteomics IDEntifications) database project files into a single consolidated CSV file. It's designed to work within Google Colab and integrates with the broader ZooMS data analysis pipeline.\n",
        "\n",
        "## Features\n",
        "- Automatically finds and processes all metadata JSON files in the specified directory\n",
        "- Flattens nested JSON structures into a tabular format\n",
        "- Handles various data types (lists, nested dictionaries, dates)\n",
        "- Creates timestamped CSV exports for version control\n",
        "- Provides detailed column information and data summaries\n",
        "- Integrates with Google Drive for storage\n",
        "\n",
        "## Prerequisites\n",
        "- Google Colab environment\n",
        "- Access to Google Drive with ZooMS_Data/PRIDE directory\n",
        "- Python packages: pandas, tqdm\n",
        "\n",
        "## Configuration Parameters\n",
        "```python\n",
        "shared_drive_base_dir_str = \"/content/drive/Shareddrives/ZooMS_Data/PRIDE\"\n",
        "spreadsheet_id = '127K6zdl5y46DRqUwRr-V32nUDoceaddbhG9XyozJs-4'\n",
        "sheet_name = 'PX Hominins'\n",
        "folder_name = 'Hominins'\n",
        "```\n",
        "\n",
        "## Output Structure\n",
        "The script creates a timestamped CSV file in the specified folder:\n",
        "```\n",
        "/content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/\n",
        "└── pride_metadata_aggregated_YYYYMMDD_HHMMSS.csv\n",
        "```\n",
        "\n",
        "## Output Format\n",
        "The CSV includes:\n",
        "- PRIDE project IDs as the first column\n",
        "- All metadata fields as additional columns\n",
        "- Flattened nested structures with intuitive column names\n",
        "- Lists converted to comma-separated strings\n",
        "- Dates in standardized datetime format\n",
        "\n",
        "## Usage\n",
        "1. Mount Google Drive and authenticate\n",
        "2. Configure folder parameters if needed\n",
        "3. Run the script\n",
        "4. Check the output directory for the generated CSV\n",
        "5. Review the console output for data summary and column information\n",
        "\n",
        "## Data Processing Details\n",
        "The script:\n",
        "1. Recursively finds all non-mapped metadata JSON files\n",
        "2. Processes each file:\n",
        "   - Extracts PRIDE ID from filename\n",
        "   - Loads and parses JSON content\n",
        "   - Flattens nested structures\n",
        "   - Standardizes data types\n",
        "3. Combines all data into a single DataFrame\n",
        "4. Exports to CSV with timestamp\n",
        "\n",
        "## Error Handling\n",
        "- Logs errors for invalid JSON files\n",
        "- Skips problematic files while continuing processing\n",
        "- Reports processing statistics\n",
        "- Provides detailed error messages for troubleshooting\n",
        "\n",
        "## Notes\n",
        "- Files with '_mapped' suffix are excluded\n",
        "- Each export creates a new timestamped file\n",
        "- Column names are preserved from original metadata\n",
        "- Date fields are automatically converted to datetime format\n",
        "\n",
        "## Dependencies\n",
        "- pandas: Data processing and CSV export\n",
        "- pathlib: File path handling\n",
        "- google.colab: Drive mounting and authentication\n",
        "- tqdm: Progress tracking"
      ],
      "metadata": {
        "id": "I37u47QXcJog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "yYgNmCNmcYqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1:Import Dependencies\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict\n",
        "from google.colab import drive, auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "5e7-mMZX9sy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 (Code) - Drive Mounting and Initial Setup\n",
        "# def setup_drive():\n",
        "#     \"\"\"Mount Google Drive with proper error handling.\"\"\"\n",
        "#     mount_point = '/content/drive'\n",
        "\n",
        "#     if os.path.exists(mount_point) and os.path.isdir(mount_point):\n",
        "#         try:\n",
        "#             os.listdir(mount_point)\n",
        "#             print(\"Google Drive is already mounted.\")\n",
        "#         except:\n",
        "#             print(\"Remounting Google Drive...\")\n",
        "#             drive.mount(mount_point, force_remount=True)\n",
        "#     else:\n",
        "#         print(\"Mounting Google Drive...\")\n",
        "#         drive.mount(mount_point)\n",
        "\n",
        "#     # Authenticate for Google services\n",
        "#     print(\"Authenticating...\")\n",
        "#     auth.authenticate_user()\n",
        "\n",
        "# Mount Google Drive\n",
        "mount_point = '/content/drive'\n",
        "\n",
        "if os.path.exists(mount_point) and os.path.isdir(mount_point):\n",
        "    try:\n",
        "        os.listdir(mount_point)\n",
        "        print(\"Google Drive is already mounted.\")\n",
        "    except:\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount(mount_point)\n",
        "else:\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount(mount_point)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QmFm5FJndLH",
        "outputId": "f1e5cba8-faab-457d-a4ad-8e8950bd7301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make Selections"
      ],
      "metadata": {
        "id": "z7RbsJTscdKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 (Code) - Configuration\n",
        "shared_drive_base_dir_str = \"/content/drive/Shareddrives/ZooMS_Data/PRIDE\"  # @param {type:\"string\"}\n",
        "folder_name = \"Hominins\"  # @param {type:\"string\"}\n",
        "\n",
        "# Create base directory if it doesn't exist\n",
        "base_dir = Path(shared_drive_base_dir_str) / folder_name\n",
        "base_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "js_SDSW4CXfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cell 3 (Code) - Configuration\n",
        "# # --- Module Parameters ---\n",
        "# shared_drive_base_dir_str = \"/content/drive/Shareddrives/ZooMS_Data/PRIDE\"  # @param {type:\"string\"}\n",
        "# spreadsheet_id = '127K6zdl5y46DRqUwRr-V32nUDoceaddbhG9XyozJs-4'  # @param {type:\"string\"}\n",
        "# sheet_name = 'PX Hominins'  # @param {type:\"string\"}\n",
        "# folder_name = 'Hominins'  # @param {type:\"string\"}\n",
        "\n",
        "# # Create base directory if it doesn't exist\n",
        "# os.makedirs(shared_drive_base_dir_str, exist_ok=True)\n",
        "# os.chdir(shared_drive_base_dir_str)\n",
        "\n",
        "# # Configure logging\n",
        "# logging.basicConfig(\n",
        "#     level=logging.INFO,\n",
        "#     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "# )\n",
        "# logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "GJQK5xmc2qdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 (Code) - Class Definitions\n",
        "@dataclass\n",
        "class MetadataConfig:\n",
        "    \"\"\"Configuration for metadata processing.\"\"\"\n",
        "    base_dir: str\n",
        "    folder_name: str\n",
        "    timestamp_format: str = \"%Y%m%d_%H%M%S\"\n",
        "    date_columns: List[str] = None\n",
        "    ignored_fields: List[str] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.date_columns = self.date_columns or ['publicationDate', 'submissionDate', 'updatedDate']\n",
        "        self.ignored_fields = self.ignored_fields or ['_mapped']\n",
        "        self.full_path = Path(self.base_dir) / self.folder_name\n",
        "\n",
        "# class MetadataProcessor:\n",
        "#     \"\"\"Handles PRIDE metadata processing and aggregation.\"\"\"\n",
        "\n",
        "#     def __init__(self, config: MetadataConfig):\n",
        "#         self.config = config\n",
        "#         self.logger = logging.getLogger(__name__)\n",
        "\n",
        "#         # Create logs directory\n",
        "#         self.logs_dir = self.config.full_path / 'logs'\n",
        "#         self.logs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#         self._setup_logging()\n",
        "\n",
        "#     def _setup_logging(self):\n",
        "#         \"\"\"Configure logging with file and console handlers.\"\"\"\n",
        "#         log_file = self.logs_dir / f\"metadata_processing_{datetime.now().strftime(self.config.timestamp_format)}.log\"\n",
        "#         file_handler = logging.FileHandler(log_file)\n",
        "#         console_handler = logging.StreamHandler()\n",
        "\n",
        "#         formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "#         file_handler.setFormatter(formatter)\n",
        "#         console_handler.setFormatter(formatter)\n",
        "\n",
        "#         self.logger.addHandler(file_handler)\n",
        "#         self.logger.addHandler(console_handler)\n",
        "#         self.logger.setLevel(logging.INFO)\n",
        "\n",
        "#     def find_metadata_files(self) -> List[Path]:\n",
        "#         \"\"\"Find metadata JSON files in PXD folders.\"\"\"\n",
        "#         metadata_files = []\n",
        "\n",
        "#         # Check main directory\n",
        "#         if not self.config.full_path.exists():\n",
        "#             self.logger.error(f\"Directory does not exist: {self.config.full_path}\")\n",
        "#             return []\n",
        "\n",
        "#         # Look for metadata files in PXD folders with specific naming pattern\n",
        "#         for pxd_dir in self.config.full_path.glob(\"PXD*\"):\n",
        "#             if pxd_dir.is_dir():\n",
        "#                 expected_file = pxd_dir / f\"{pxd_dir.name}_metadata.json\"\n",
        "#                 if expected_file.exists():\n",
        "#                     self.logger.info(f\"Found metadata file: {expected_file}\")\n",
        "#                     metadata_files.append(expected_file)\n",
        "#                 else:\n",
        "#                     self.logger.warning(f\"No metadata file found in {pxd_dir.name}\")\n",
        "\n",
        "#         self.logger.info(f\"Found {len(metadata_files)} metadata files in PXD folders\")\n",
        "#         return metadata_files\n",
        "\n",
        "#     #staticmethod\n",
        "#     def flatten_dict(d: Dict, parent_key: str = '', sep: str = '_') -> Dict:\n",
        "#         \"\"\"Flatten nested dictionary with improved handling of complex structures.\"\"\"\n",
        "#         items = []\n",
        "\n",
        "#         # Special handling for file statistics\n",
        "#         if parent_key == 'fileStats' and isinstance(d, dict):\n",
        "#             for category, stats in d.get('filesByCategory', {}).items():\n",
        "#                 items.extend([\n",
        "#                     (f\"files_{category}_count\", stats['count']),\n",
        "#                     (f\"files_{category}_size_bytes\", stats['totalSize']),\n",
        "#                     (f\"files_{category}_downloads\", stats['totalDownloads'])\n",
        "#                 ])\n",
        "#             if 'totalFiles' in d:\n",
        "#                 items.append(('total_files', d['totalFiles']))\n",
        "#             if 'totalDownloads' in d:\n",
        "#                 items.append(('total_downloads', d['totalDownloads']))\n",
        "#             return dict(items)\n",
        "\n",
        "#         for k, v in d.items():\n",
        "#             new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "\n",
        "#             if isinstance(v, dict):\n",
        "#                 items.extend(MetadataProcessor.flatten_dict(v, new_key, sep=sep).items())\n",
        "#             elif isinstance(v, list):\n",
        "#                 if v and isinstance(v[0], dict):\n",
        "#                     # Extract meaningful values from list of dictionaries\n",
        "#                     values = []\n",
        "#                     for item in v:\n",
        "#                         if isinstance(item, dict):\n",
        "#                             for field in ['name', 'value', 'accession', 'id']:\n",
        "#                                 if field in item:\n",
        "#                                     values.append(str(item[field]))\n",
        "#                                     break\n",
        "#                             else:\n",
        "#                                 values.append(str(next(iter(item.values()))))\n",
        "#                         else:\n",
        "#                             values.append(str(item))\n",
        "#                     items.append((new_key, ' | '.join(values)))\n",
        "#                 else:\n",
        "#                     items.append((new_key, ' | '.join(map(str, v))))\n",
        "#             else:\n",
        "#                 items.append((new_key, v))\n",
        "\n",
        "#         return dict(items)\n",
        "\n",
        "# def load_metadata_file(self, file_path: Path) -> Optional[Dict]:\n",
        "#     \"\"\"Load and validate metadata JSON file.\"\"\"\n",
        "#     try:\n",
        "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
        "#             data = json.load(f)\n",
        "\n",
        "#             # If data is a list of file metadata, aggregate it\n",
        "#             if isinstance(data, list):\n",
        "#                 # Create aggregated metadata\n",
        "#                 aggregated = {\n",
        "#                     \"projectAccessions\": data[0][\"projectAccessions\"] if data else [],\n",
        "#                     \"files\": data,  # Keep all file information\n",
        "#                     \"submissionDate\": data[0][\"submissionDate\"] if data else None,\n",
        "#                     \"publicationDate\": data[0][\"publicationDate\"] if data else None,\n",
        "#                     \"updatedDate\": data[0][\"updatedDate\"] if data else None,\n",
        "#                     # Add file statistics\n",
        "#                     \"fileStats\": {\n",
        "#                         \"totalFiles\": len(data),\n",
        "#                         \"totalDownloads\": sum(file.get(\"totalDownloads\", 0) for file in data),\n",
        "#                         \"filesByCategory\": {}\n",
        "#                     }\n",
        "#                 }\n",
        "\n",
        "#                 # Calculate file statistics by category\n",
        "#                 for file in data:\n",
        "#                     category = file.get(\"fileCategory\", {}).get(\"value\", \"UNKNOWN\")\n",
        "#                     if category not in aggregated[\"fileStats\"][\"filesByCategory\"]:\n",
        "#                         aggregated[\"fileStats\"][\"filesByCategory\"][category] = {\n",
        "#                             \"count\": 0,\n",
        "#                             \"totalSize\": 0,\n",
        "#                             \"totalDownloads\": 0\n",
        "#                         }\n",
        "#                     stats = aggregated[\"fileStats\"][\"filesByCategory\"][category]\n",
        "#                     stats[\"count\"] += 1\n",
        "#                     stats[\"totalSize\"] += file.get(\"fileSizeBytes\", 0)\n",
        "#                     stats[\"totalDownloads\"] += file.get(\"totalDownloads\", 0)\n",
        "\n",
        "#                 return aggregated\n",
        "#             elif isinstance(data, dict):\n",
        "#                 return data\n",
        "#             else:\n",
        "#                 self.logger.warning(f\"Invalid metadata format in {file_path}\")\n",
        "#                 return None\n",
        "#     except json.JSONDecodeError as e:\n",
        "#         self.logger.error(f\"JSON parsing error in {file_path}: {e}\")\n",
        "#         return None\n",
        "#     except Exception as e:\n",
        "#         self.logger.error(f\"Error reading {file_path}: {e}\")\n",
        "#         return None\n",
        "\n",
        "#     def process_metadata(self) -> pd.DataFrame:\n",
        "#         \"\"\"Process all metadata files into a DataFrame.\"\"\"\n",
        "#         metadata_files = self.find_metadata_files()\n",
        "#         if not metadata_files:\n",
        "#             self.logger.error(f\"No metadata files found in {self.config.full_path}\")\n",
        "#             return pd.DataFrame()\n",
        "\n",
        "#         all_data = []\n",
        "#         for file_path in tqdm(metadata_files, desc=\"Processing metadata files\"):\n",
        "#             try:\n",
        "#                 pride_id = file_path.stem.replace('_metadata', '')\n",
        "#                 metadata = self.load_metadata_file(file_path)\n",
        "\n",
        "#                 if metadata:\n",
        "#                     flat_metadata = self.flatten_dict(metadata)\n",
        "#                     flat_metadata['pride_id'] = pride_id\n",
        "#                     all_data.append(flat_metadata)\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 self.logger.error(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "#         if not all_data:\n",
        "#             self.logger.error(\"No valid metadata found\")\n",
        "#             return pd.DataFrame()\n",
        "\n",
        "#         df = pd.DataFrame(all_data)\n",
        "#         return self._post_process_dataframe(df)\n",
        "\n",
        "class MetadataProcessor:\n",
        "    \"\"\"Handles PRIDE metadata processing and aggregation.\"\"\"\n",
        "\n",
        "    def __init__(self, config: MetadataConfig):\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # Create logs directory\n",
        "        self.logs_dir = self.config.full_path / 'logs'\n",
        "        self.logs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self._setup_logging()\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        \"\"\"Configure logging with file and console handlers.\"\"\"\n",
        "        log_file = self.logs_dir / f\"metadata_processing_{datetime.now().strftime(self.config.timestamp_format)}.log\"\n",
        "        file_handler = logging.FileHandler(log_file)\n",
        "        console_handler = logging.StreamHandler()\n",
        "\n",
        "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "        file_handler.setFormatter(formatter)\n",
        "        console_handler.setFormatter(formatter)\n",
        "\n",
        "        self.logger.addHandler(file_handler)\n",
        "        self.logger.addHandler(console_handler)\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "\n",
        "    def find_metadata_files(self) -> List[Path]:\n",
        "        \"\"\"Find metadata JSON files in PXD folders.\"\"\"\n",
        "        metadata_files = []\n",
        "\n",
        "        # Check main directory\n",
        "        if not self.config.full_path.exists():\n",
        "            self.logger.error(f\"Directory does not exist: {self.config.full_path}\")\n",
        "            return []\n",
        "\n",
        "        # Look for metadata files in PXD folders with specific naming pattern\n",
        "        for pxd_dir in self.config.full_path.glob(\"PXD*\"):\n",
        "            if pxd_dir.is_dir():\n",
        "                expected_file = pxd_dir / f\"{pxd_dir.name}_metadata.json\"\n",
        "                if expected_file.exists():\n",
        "                    self.logger.info(f\"Found metadata file: {expected_file}\")\n",
        "                    metadata_files.append(expected_file)\n",
        "                else:\n",
        "                    self.logger.warning(f\"No metadata file found in {pxd_dir.name}\")\n",
        "\n",
        "        self.logger.info(f\"Found {len(metadata_files)} metadata files in PXD folders\")\n",
        "        return metadata_files\n",
        "\n",
        "    def load_metadata_file(self, file_path: Path) -> Optional[Dict]:\n",
        "        \"\"\"Load and validate metadata JSON file.\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "                # If data is a list of file metadata, aggregate it\n",
        "                if isinstance(data, list):\n",
        "                    # Create aggregated metadata\n",
        "                    aggregated = {\n",
        "                        \"projectAccessions\": data[0][\"projectAccessions\"] if data else [],\n",
        "                        \"files\": data,  # Keep all file information\n",
        "                        \"submissionDate\": data[0][\"submissionDate\"] if data else None,\n",
        "                        \"publicationDate\": data[0][\"publicationDate\"] if data else None,\n",
        "                        \"updatedDate\": data[0][\"updatedDate\"] if data else None,\n",
        "                        \"fileStats\": {\n",
        "                            \"totalFiles\": len(data),\n",
        "                            \"totalDownloads\": sum(file.get(\"totalDownloads\", 0) for file in data),\n",
        "                            \"filesByCategory\": {}\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    # Calculate file statistics by category\n",
        "                    for file in data:\n",
        "                        category = file.get(\"fileCategory\", {}).get(\"value\", \"UNKNOWN\")\n",
        "                        if category not in aggregated[\"fileStats\"][\"filesByCategory\"]:\n",
        "                            aggregated[\"fileStats\"][\"filesByCategory\"][category] = {\n",
        "                                \"count\": 0,\n",
        "                                \"totalSize\": 0,\n",
        "                                \"totalDownloads\": 0\n",
        "                            }\n",
        "                        stats = aggregated[\"fileStats\"][\"filesByCategory\"][category]\n",
        "                        stats[\"count\"] += 1\n",
        "                        stats[\"totalSize\"] += file.get(\"fileSizeBytes\", 0)\n",
        "                        stats[\"totalDownloads\"] += file.get(\"totalDownloads\", 0)\n",
        "\n",
        "                    return aggregated\n",
        "                elif isinstance(data, dict):\n",
        "                    return data\n",
        "                else:\n",
        "                    self.logger.warning(f\"Invalid metadata format in {file_path}\")\n",
        "                    return None\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"JSON parsing error in {file_path}: {e}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error reading {file_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def flatten_dict(d: Dict, parent_key: str = '', sep: str = '_') -> Dict:\n",
        "        \"\"\"Flatten nested dictionary with improved handling of complex structures.\"\"\"\n",
        "        items = []\n",
        "\n",
        "        # Special handling for file statistics\n",
        "        if parent_key == 'fileStats' and isinstance(d, dict):\n",
        "            for category, stats in d.get('filesByCategory', {}).items():\n",
        "                items.extend([\n",
        "                    (f\"files_{category}_count\", stats['count']),\n",
        "                    (f\"files_{category}_size_bytes\", stats['totalSize']),\n",
        "                    (f\"files_{category}_downloads\", stats['totalDownloads'])\n",
        "                ])\n",
        "            if 'totalFiles' in d:\n",
        "                items.append(('total_files', d['totalFiles']))\n",
        "            if 'totalDownloads' in d:\n",
        "                items.append(('total_downloads', d['totalDownloads']))\n",
        "            return dict(items)\n",
        "\n",
        "        for k, v in d.items():\n",
        "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "\n",
        "            if isinstance(v, dict):\n",
        "                items.extend(MetadataProcessor.flatten_dict(v, new_key, sep=sep).items())\n",
        "            elif isinstance(v, list):\n",
        "                if v and isinstance(v[0], dict):\n",
        "                    values = []\n",
        "                    for item in v:\n",
        "                        if isinstance(item, dict):\n",
        "                            for field in ['name', 'value', 'accession', 'id']:\n",
        "                                if field in item:\n",
        "                                    values.append(str(item[field]))\n",
        "                                    break\n",
        "                            else:\n",
        "                                values.append(str(next(iter(item.values()))))\n",
        "                        else:\n",
        "                            values.append(str(item))\n",
        "                    items.append((new_key, ' | '.join(values)))\n",
        "                else:\n",
        "                    items.append((new_key, ' | '.join(map(str, v))))\n",
        "            else:\n",
        "                items.append((new_key, v))\n",
        "\n",
        "        return dict(items)\n",
        "\n",
        "    def process_metadata(self) -> pd.DataFrame:\n",
        "        \"\"\"Process all metadata files into a DataFrame.\"\"\"\n",
        "        metadata_files = self.find_metadata_files()\n",
        "        if not metadata_files:\n",
        "            self.logger.error(f\"No metadata files found in {self.config.full_path}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        all_data = []\n",
        "        for file_path in tqdm(metadata_files, desc=\"Processing metadata files\"):\n",
        "            try:\n",
        "                pride_id = file_path.stem.replace('_metadata', '')\n",
        "                metadata = self.load_metadata_file(file_path)\n",
        "\n",
        "                if metadata:\n",
        "                    flat_metadata = self.flatten_dict(metadata)\n",
        "                    flat_metadata['pride_id'] = pride_id\n",
        "                    all_data.append(flat_metadata)\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "        if not all_data:\n",
        "            self.logger.error(\"No valid metadata found\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame(all_data)\n",
        "        return self._post_process_dataframe(df)\n",
        "\n",
        "    def _post_process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Apply post-processing to the DataFrame.\"\"\"\n",
        "        # Ensure pride_id is first column\n",
        "        cols = ['pride_id'] + [col for col in df.columns if col != 'pride_id']\n",
        "        df = df[cols]\n",
        "\n",
        "        # Convert date columns\n",
        "        for col in self.config.date_columns:\n",
        "            if col in df.columns:\n",
        "                try:\n",
        "                    df[col] = pd.to_datetime(df[col])\n",
        "                except Exception as e:\n",
        "                    self.logger.warning(f\"Failed to convert {col} to datetime: {e}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def export_dataframe(self, df: pd.DataFrame) -> Path:\n",
        "        \"\"\"Export DataFrame with timestamp.\"\"\"\n",
        "        timestamp = datetime.now().strftime(self.config.timestamp_format)\n",
        "        filename = f\"pride_metadata_aggregated_{timestamp}.csv\"\n",
        "        output_path = self.config.full_path / filename\n",
        "\n",
        "        try:\n",
        "            df.to_csv(output_path, index=False, encoding='utf-8')\n",
        "            self.logger.info(f\"Data exported to {output_path}\")\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Export failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def generate_summary(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
        "        \"\"\"Generate comprehensive summary statistics.\"\"\"\n",
        "        return {\n",
        "            \"total_projects\": len(df),\n",
        "            \"total_fields\": len(df.columns),\n",
        "            \"date_range\": {\n",
        "                col: {\n",
        "                    \"min\": df[col].min(),\n",
        "                    \"max\": df[col].max()\n",
        "                } for col in self.config.date_columns if col in df.columns\n",
        "            },\n",
        "            \"field_stats\": {\n",
        "                col: {\n",
        "                    \"type\": str(df[col].dtype),\n",
        "                    \"non_null\": df[col].count(),\n",
        "                    \"unique_values\": df[col].nunique()\n",
        "                } for col in df.columns\n",
        "            }\n",
        "        }\n"
      ],
      "metadata": {
        "id": "91UFZ-ca4lSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 (Code) - Main Function\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "    print(\"Starting PRIDE metadata aggregation...\")\n",
        "\n",
        "    try:\n",
        "        # Create configuration\n",
        "        config = MetadataConfig(\n",
        "            base_dir=shared_drive_base_dir_str,\n",
        "            folder_name=folder_name\n",
        "        )\n",
        "\n",
        "        print(\"Initializing metadata processor...\")\n",
        "        processor = MetadataProcessor(config)\n",
        "\n",
        "        df = processor.process_metadata()\n",
        "        if not df.empty:\n",
        "            output_path = processor.export_dataframe(df)\n",
        "            summary = processor.generate_summary(df)\n",
        "\n",
        "            print(f\"\\nProcessing complete!\")\n",
        "            print(f\"Output file: {output_path}\")\n",
        "            print(f\"\\nSummary:\")\n",
        "            print(f\"Total projects: {summary['total_projects']}\")\n",
        "            print(f\"Total metadata fields: {summary['total_fields']}\")\n",
        "\n",
        "            print(\"\\nField statistics:\")\n",
        "            for field, stats in summary['field_stats'].items():\n",
        "                print(f\"\\n{field}:\")\n",
        "                print(f\"  Type: {stats['type']}\")\n",
        "                print(f\"  Non-null count: {stats['non_null']}\")\n",
        "                print(f\"  Unique values: {stats['unique_values']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Processing failed: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "OzDtn2ZX7lzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Script"
      ],
      "metadata": {
        "id": "FMmpOms-chw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 (Code) - Execution\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "rvKXm1PVjepl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e75699f323a1409091dcdb99f0a104dc",
            "f46a07c6969340adbaa8bed1fed5ac05",
            "90893764148049f586a4a4d747c73c22",
            "096cee408880456e91c49592ab98e5e8",
            "de339ba7e798423c91421b4dfe2619ac",
            "a45e19239ac84a1f8094cfd39c158d9e",
            "9c422c2dfb6d4c89a4cc317d68af8636",
            "552c802433484fb0854afef8c2baafa8",
            "0cbde74e877c4c9b8ccb38a3ce233296",
            "385121cef0c74f149e915b86dcb21a48",
            "bfafcc5b1bbb4ba0be87779b699227bd"
          ]
        },
        "outputId": "3ec76c67-c912-4abf-83f9-d27e3d19e210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-22 14:33:43,428 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018721/PXD018721_metadata.json\n",
            "2025-02-22 14:33:43,428 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018721/PXD018721_metadata.json\n",
            "2025-02-22 14:33:43,428 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018721/PXD018721_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018721/PXD018721_metadata.json\n",
            "2025-02-22 14:33:43,436 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD020530/PXD020530_metadata.json\n",
            "2025-02-22 14:33:43,436 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD020530/PXD020530_metadata.json\n",
            "2025-02-22 14:33:43,436 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD020530/PXD020530_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD020530/PXD020530_metadata.json\n",
            "2025-02-22 14:33:43,441 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD011377/PXD011377_metadata.json\n",
            "2025-02-22 14:33:43,441 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD011377/PXD011377_metadata.json\n",
            "2025-02-22 14:33:43,441 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD011377/PXD011377_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD011377/PXD011377_metadata.json\n",
            "2025-02-22 14:33:43,448 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD045412/PXD045412_metadata.json\n",
            "2025-02-22 14:33:43,448 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD045412/PXD045412_metadata.json\n",
            "2025-02-22 14:33:43,448 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD045412/PXD045412_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD045412/PXD045412_metadata.json\n",
            "2025-02-22 14:33:43,454 - __main__ - WARNING - No metadata file found in PXD058447\n",
            "2025-02-22 14:33:43,454 - __main__ - WARNING - No metadata file found in PXD058447\n",
            "2025-02-22 14:33:43,454 - __main__ - WARNING - No metadata file found in PXD058447\n",
            "WARNING:__main__:No metadata file found in PXD058447\n",
            "2025-02-22 14:33:43,458 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD003208/PXD003208_metadata.json\n",
            "2025-02-22 14:33:43,458 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD003208/PXD003208_metadata.json\n",
            "2025-02-22 14:33:43,458 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD003208/PXD003208_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD003208/PXD003208_metadata.json\n",
            "2025-02-22 14:33:43,462 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018264/PXD018264_metadata.json\n",
            "2025-02-22 14:33:43,462 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018264/PXD018264_metadata.json\n",
            "2025-02-22 14:33:43,462 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018264/PXD018264_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD018264/PXD018264_metadata.json\n",
            "2025-02-22 14:33:43,466 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD043272/PXD043272_metadata.json\n",
            "2025-02-22 14:33:43,466 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD043272/PXD043272_metadata.json\n",
            "2025-02-22 14:33:43,466 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD043272/PXD043272_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD043272/PXD043272_metadata.json\n",
            "2025-02-22 14:33:43,469 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD047932/PXD047932_metadata.json\n",
            "2025-02-22 14:33:43,469 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD047932/PXD047932_metadata.json\n",
            "2025-02-22 14:33:43,469 - __main__ - INFO - Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD047932/PXD047932_metadata.json\n",
            "INFO:__main__:Found metadata file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/PXD047932/PXD047932_metadata.json\n",
            "2025-02-22 14:33:43,472 - __main__ - INFO - Found 8 metadata files in PXD folders\n",
            "2025-02-22 14:33:43,472 - __main__ - INFO - Found 8 metadata files in PXD folders\n",
            "2025-02-22 14:33:43,472 - __main__ - INFO - Found 8 metadata files in PXD folders\n",
            "INFO:__main__:Found 8 metadata files in PXD folders\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting PRIDE metadata aggregation...\n",
            "Initializing metadata processor...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing metadata files:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e75699f323a1409091dcdb99f0a104dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-22 14:33:43,586 - __main__ - INFO - Data exported to /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/pride_metadata_aggregated_20250222_143343.csv\n",
            "2025-02-22 14:33:43,586 - __main__ - INFO - Data exported to /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/pride_metadata_aggregated_20250222_143343.csv\n",
            "2025-02-22 14:33:43,586 - __main__ - INFO - Data exported to /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/pride_metadata_aggregated_20250222_143343.csv\n",
            "INFO:__main__:Data exported to /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/pride_metadata_aggregated_20250222_143343.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing complete!\n",
            "Output file: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins/pride_metadata_aggregated_20250222_143343.csv\n",
            "\n",
            "Summary:\n",
            "Total projects: 8\n",
            "Total metadata fields: 23\n",
            "\n",
            "Field statistics:\n",
            "\n",
            "pride_id:\n",
            "  Type: object\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "projectAccessions:\n",
            "  Type: object\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "files:\n",
            "  Type: object\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "submissionDate:\n",
            "  Type: datetime64[ns, UTC]\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "publicationDate:\n",
            "  Type: datetime64[ns, UTC]\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "updatedDate:\n",
            "  Type: datetime64[ns, UTC]\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "files_OTHER_count:\n",
            "  Type: float64\n",
            "  Non-null count: 5\n",
            "  Unique values: 4\n",
            "\n",
            "files_OTHER_size_bytes:\n",
            "  Type: float64\n",
            "  Non-null count: 5\n",
            "  Unique values: 5\n",
            "\n",
            "files_OTHER_downloads:\n",
            "  Type: float64\n",
            "  Non-null count: 5\n",
            "  Unique values: 4\n",
            "\n",
            "files_RAW_count:\n",
            "  Type: int64\n",
            "  Non-null count: 8\n",
            "  Unique values: 6\n",
            "\n",
            "files_RAW_size_bytes:\n",
            "  Type: int64\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "files_RAW_downloads:\n",
            "  Type: int64\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "files_SEARCH_count:\n",
            "  Type: float64\n",
            "  Non-null count: 5\n",
            "  Unique values: 4\n",
            "\n",
            "files_SEARCH_size_bytes:\n",
            "  Type: float64\n",
            "  Non-null count: 5\n",
            "  Unique values: 5\n",
            "\n",
            "files_SEARCH_downloads:\n",
            "  Type: float64\n",
            "  Non-null count: 5\n",
            "  Unique values: 5\n",
            "\n",
            "total_files:\n",
            "  Type: int64\n",
            "  Non-null count: 8\n",
            "  Unique values: 6\n",
            "\n",
            "total_downloads:\n",
            "  Type: int64\n",
            "  Non-null count: 8\n",
            "  Unique values: 8\n",
            "\n",
            "files_PEAK_count:\n",
            "  Type: float64\n",
            "  Non-null count: 3\n",
            "  Unique values: 3\n",
            "\n",
            "files_PEAK_size_bytes:\n",
            "  Type: float64\n",
            "  Non-null count: 3\n",
            "  Unique values: 3\n",
            "\n",
            "files_PEAK_downloads:\n",
            "  Type: float64\n",
            "  Non-null count: 3\n",
            "  Unique values: 3\n",
            "\n",
            "files_RESULT_count:\n",
            "  Type: float64\n",
            "  Non-null count: 3\n",
            "  Unique values: 3\n",
            "\n",
            "files_RESULT_size_bytes:\n",
            "  Type: float64\n",
            "  Non-null count: 3\n",
            "  Unique values: 3\n",
            "\n",
            "files_RESULT_downloads:\n",
            "  Type: float64\n",
            "  Non-null count: 3\n",
            "  Unique values: 3\n"
          ]
        }
      ]
    }
  ]
}