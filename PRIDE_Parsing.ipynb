{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfOvRxZ/T3PxPb7IDMzMM7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palaeoprot/PRIDE/blob/main/PRIDE_Parsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- Configuration ---\n",
        "# FIX: Change the input file to point to the actual XML file, not HTML\n",
        "INPUT_XML = '/content/PXD058447.xml'  # Updated to use the correct XML file\n",
        "OUTPUT_CSV = '/content/proteomex_data_extracted.csv'\n",
        "\n",
        "# Namespace handling\n",
        "NS = {\n",
        "    'px': 'http://www.proteomexchange.org/schemas/ProteomeXchange.xsd',\n",
        "    'cv': 'http://psidev.info/psi/cv/1.1',\n",
        "    'xsi': 'http://www.w3.org/2001/XMLSchema-instance'\n",
        "}\n",
        "\n",
        "# Map accession numbers to readable names for CV parameters\n",
        "CV_MAP = {\n",
        "    # Species\n",
        "    'MS:1001469': 'Species Scientific Name',\n",
        "    'MS:1001467': 'NCBI TaxID',\n",
        "\n",
        "    # Review Level\n",
        "    'MS:1002854': 'Review Level',\n",
        "\n",
        "    # Repository Support\n",
        "    'MS:1002856': 'Repository Support',\n",
        "\n",
        "    # Dataset Origin\n",
        "    'MS:1002868': 'Dataset Origin',\n",
        "\n",
        "    # Contact roles\n",
        "    'MS:1000586': 'Contact Name',\n",
        "    'MS:1000589': 'Contact Email',\n",
        "    'MS:1000590': 'Contact Affiliation',\n",
        "    'MS:1002037': 'Role: Dataset Submitter',\n",
        "    'MS:1002332': 'Role: Lab Head',\n",
        "\n",
        "    # Publication\n",
        "    'MS:1001922': 'Publication DOI',\n",
        "\n",
        "    # Keyword\n",
        "    'MS:1001925': 'Keyword',\n",
        "\n",
        "    # File types\n",
        "    'MS:1002846': 'Associated raw file',\n",
        "    'MS:1002850': 'Peak list file',\n",
        "    'MS:1002848': 'Result file',\n",
        "    'MS:1002851': 'Other type file',\n",
        "\n",
        "    # Dataset links\n",
        "    'MS:1002852': 'Dataset FTP Location',\n",
        "    'MS:1001930': 'PRIDE Project URI',\n",
        "}\n",
        "\n",
        "\n",
        "def parse_xml(file_path):\n",
        "    \"\"\"Parse the ProteomeXchange XML file.\"\"\"\n",
        "    try:\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "        print(f\"‚úÖ Successfully parsed XML file: {file_path}\")\n",
        "        print(f\"üìÑ Root element: {root.tag}\")\n",
        "        return root\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"‚ùå XML Parse Error: {e}\")\n",
        "        print(f\"üí° Make sure you're using the XML file, not HTML!\")\n",
        "        return None\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"‚ùå File not found: {e}\")\n",
        "        print(f\"üí° Available files to check:\")\n",
        "        import os\n",
        "        if os.path.exists('/content'):\n",
        "            for f in os.listdir('/content'):\n",
        "                if f.endswith(('.xml', '.html')):\n",
        "                    print(f\"   - {f}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_cv_value(cv_param, default_name=\"Unknown\"):\n",
        "    \"\"\"Extract name and value from cvParam using mapping.\"\"\"\n",
        "    accession = cv_param.get('accession')\n",
        "    name = CV_MAP.get(accession, cv_param.get('name', default_name))\n",
        "    value = cv_param.get('value')\n",
        "    return name, value\n",
        "\n",
        "\n",
        "def extract_dataset_identifier(root):\n",
        "    \"\"\"Extract dataset identifiers like PXD and DOI.\"\"\"\n",
        "    data = {}\n",
        "    for identifier in root.findall('.//DatasetIdentifier'):\n",
        "        for cv in identifier.findall('cvParam'):\n",
        "            name, value = get_cv_value(cv)\n",
        "            if 'accession' in name.lower():\n",
        "                data['PXD Accession'] = value\n",
        "            elif 'doi' in name.lower():\n",
        "                data['DOI'] = value\n",
        "    return data\n",
        "\n",
        "\n",
        "def extract_summary(root):\n",
        "    \"\"\"Extract dataset summary.\"\"\"\n",
        "    summary = root.find('DatasetSummary')\n",
        "    if summary is None:\n",
        "        return {}\n",
        "    data = {\n",
        "        'Title': summary.get('title', ''),\n",
        "        'Announce Date': summary.get('announceDate', ''),\n",
        "        'Hosting Repository': summary.get('hostingRepository', ''),\n",
        "        'Description': summary.findtext('Description', '').strip(),\n",
        "    }\n",
        "\n",
        "    # Review Level\n",
        "    review = summary.find('.//ReviewLevel/cvParam')\n",
        "    if review is not None:\n",
        "        _, value = get_cv_value(review)\n",
        "        data['Review Level'] = value\n",
        "\n",
        "    # Repository Support\n",
        "    support = summary.find('.//RepositorySupport/cvParam')\n",
        "    if support is not None:\n",
        "        _, value = get_cv_value(support)\n",
        "        data['Repository Support'] = value\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def extract_species(root):\n",
        "    \"\"\"Extract species information.\"\"\"\n",
        "    data = {}\n",
        "    species = root.find('SpeciesList/Species')\n",
        "    if species is not None:\n",
        "        for cv in species.findall('cvParam'):\n",
        "            name, value = get_cv_value(cv)\n",
        "            if 'scientific' in name.lower():\n",
        "                data['Species'] = value\n",
        "            elif 'taxid' in name.lower():\n",
        "                data['TaxID'] = value\n",
        "    return data\n",
        "\n",
        "\n",
        "def extract_instruments(root):\n",
        "    \"\"\"Extract instrument models.\"\"\"\n",
        "    instruments = []\n",
        "    for inst in root.findall('InstrumentList/Instrument'):\n",
        "        for cv in inst.findall('cvParam'):\n",
        "            if cv.get('name'):\n",
        "                instruments.append(cv.get('name'))\n",
        "    return {'Instrument': '; '.join(instruments)}\n",
        "\n",
        "\n",
        "def extract_modifications(root):\n",
        "    \"\"\"Extract modifications.\"\"\"\n",
        "    mods = []\n",
        "    for cv in root.findall('ModificationList/cvParam'):\n",
        "        name = cv.get('name')\n",
        "        accession = cv.get('accession')\n",
        "        mods.append(f\"{name} ({accession})\")\n",
        "    return {'Modifications': '; '.join(mods)}\n",
        "\n",
        "\n",
        "def extract_contacts(root):\n",
        "    \"\"\"Extract contact information.\"\"\"\n",
        "    data = {}\n",
        "    for contact in root.findall('ContactList/Contact'):\n",
        "        role = 'Contact'\n",
        "        if contact.find(\".//cvParam[@accession='MS:1002037']\") is not None:\n",
        "            role = 'Submitter'\n",
        "        elif contact.find(\".//cvParam[@accession='MS:1002332']\") is not None:\n",
        "            role = 'Lab Head'\n",
        "\n",
        "        name = email = affiliation = None\n",
        "        for cv in contact.findall('cvParam'):\n",
        "            param_name, value = get_cv_value(cv)\n",
        "            if param_name == 'Contact Name':\n",
        "                name = value\n",
        "            elif param_name == 'Contact Email':\n",
        "                email = value\n",
        "            elif param_name == 'Contact Affiliation':\n",
        "                affiliation = value\n",
        "\n",
        "        if role == 'Submitter':\n",
        "            data['Submitter Name'] = name\n",
        "            data['Submitter Email'] = email\n",
        "            data['Submitter Affiliation'] = affiliation\n",
        "        elif role == 'Lab Head':\n",
        "            data['Lab Head Name'] = name\n",
        "            data['Lab Head Email'] = email\n",
        "            data['Lab Head Affiliation'] = affiliation\n",
        "    return data\n",
        "\n",
        "\n",
        "def extract_publications(root):\n",
        "    \"\"\"Extract DOIs of publications.\"\"\"\n",
        "    dois = []\n",
        "    for pub in root.findall('PublicationList/Publication'):\n",
        "        for cv in pub.findall('cvParam'):\n",
        "            name, value = get_cv_value(cv)\n",
        "            if 'doi' in name.lower() and value:\n",
        "                dois.append(value)\n",
        "    return {'Publications (DOIs)': '; '.join(dois)}\n",
        "\n",
        "\n",
        "def extract_keywords(root):\n",
        "    \"\"\"Extract keywords.\"\"\"\n",
        "    for cv in root.findall('KeywordList/cvParam'):\n",
        "        if cv.get('value'):\n",
        "            return {'Keywords': cv.get('value')}\n",
        "    return {'Keywords': ''}\n",
        "\n",
        "\n",
        "def extract_full_dataset_links(root):\n",
        "    \"\"\"Extract FTP and PRIDE links.\"\"\"\n",
        "    data = {}\n",
        "    for link in root.findall('FullDatasetLinkList/FullDatasetLink'):\n",
        "        for cv in link.findall('cvParam'):\n",
        "            name, value = get_cv_value(cv)\n",
        "            if 'ftp' in name.lower():\n",
        "                data['FTP Location'] = value\n",
        "            elif 'pride' in name.lower():\n",
        "                data['PRIDE URI'] = value\n",
        "    return data\n",
        "\n",
        "\n",
        "def extract_files(root):\n",
        "    \"\"\"Extract all dataset files.\"\"\"\n",
        "    files = []\n",
        "    for f in root.findall('DatasetFileList/DatasetFile'):\n",
        "        file_info = {\n",
        "            'File ID': f.get('id'),\n",
        "            'File Name': f.get('name'),\n",
        "            'File Type': '',\n",
        "            'File URI': ''\n",
        "        }\n",
        "\n",
        "        for cv in f.findall('cvParam'):\n",
        "            name, value = get_cv_value(cv)\n",
        "            if 'URI' in name:\n",
        "                file_info['File URI'] = value\n",
        "            else:\n",
        "                file_info['File Type'] = name\n",
        "        files.append(file_info)\n",
        "    return files\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to parse XML and create CSV.\"\"\"\n",
        "    print(\"üîÑ Starting PRIDE XML parsing...\")\n",
        "\n",
        "    root = parse_xml(INPUT_XML)\n",
        "    if root is None:\n",
        "        print(\"‚ùå Failed to parse XML file. Please check the file path and format.\")\n",
        "        return\n",
        "\n",
        "    # Extract top-level metadata (single row)\n",
        "    print(\"üìä Extracting metadata...\")\n",
        "    metadata = {}\n",
        "    metadata.update(extract_dataset_identifier(root))\n",
        "    metadata.update(extract_summary(root))\n",
        "    metadata.update(extract_species(root))\n",
        "    metadata.update(extract_instruments(root))\n",
        "    metadata.update(extract_modifications(root))\n",
        "    metadata.update(extract_contacts(root))\n",
        "    metadata.update(extract_publications(root))\n",
        "    metadata.update(extract_keywords(root))\n",
        "    metadata.update(extract_full_dataset_links(root))\n",
        "\n",
        "    # Extract files (multiple rows)\n",
        "    print(\"üìÅ Extracting file information...\")\n",
        "    files = extract_files(root)\n",
        "\n",
        "    # If no files, add one dummy row so CSV is still valid\n",
        "    if not files:\n",
        "        files = [dict.fromkeys(['File ID', 'File Name', 'File Type', 'File URI'], '')]\n",
        "\n",
        "    # Add metadata to each file row\n",
        "    for f in files:\n",
        "        f.update({k: v for k, v in metadata.items() if k not in f})\n",
        "\n",
        "    # Write to CSV\n",
        "    print(\"üíæ Writing to CSV...\")\n",
        "    fieldnames = list(files[0].keys())\n",
        "    try:\n",
        "        with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            for row in files:\n",
        "                writer.writerow(row)\n",
        "\n",
        "        print(f\"‚úÖ Successfully extracted data to '{OUTPUT_CSV}'\")\n",
        "        print(f\"üìÅ Total files included: {len(files)}\")\n",
        "        print(f\"üìã Columns extracted: {len(fieldnames)}\")\n",
        "\n",
        "        # Show a preview of extracted data\n",
        "        print(f\"\\nüìñ Sample metadata:\")\n",
        "        print(f\"   Title: {metadata.get('Title', 'N/A')}\")\n",
        "        print(f\"   PXD: {metadata.get('PXD Accession', 'N/A')}\")\n",
        "        print(f\"   Species: {metadata.get('Species', 'N/A')}\")\n",
        "        print(f\"   Files: {len(files)} files\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error writing CSV: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXRzBrY_Gn-Z",
        "outputId": "6eae7c34-1805-49a8-ab17-3d0024ffa247"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting PRIDE XML parsing...\n",
            "‚ùå XML Parse Error: mismatched tag: line 9, column 121\n",
            "üí° Make sure you're using the XML file, not HTML!\n",
            "‚ùå Failed to parse XML file. Please check the file path and format.\n"
          ]
        }
      ]
    }
  ]
}