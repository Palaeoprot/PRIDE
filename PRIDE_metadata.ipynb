{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGOZO4YLhGBUDmIWSe1ApD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palaeoprot/PRIDE/blob/main/PRIDE_metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRIDE Metadata Extraction and Ontology Mapping**\n",
        "\n",
        "## **Project Overview**\n",
        "This project aims to extract, standardise, and analyse metadata from the **PRIDE (Proteomics Identifications Database)** repository. The goal is to:\n",
        "- **Retrieve metadata** for specific PRIDE datasets using the PRIDE API.\n",
        "- **Store metadata** in a structured format (JSON) within predefined folders.\n",
        "- **Inspect metadata fields** to identify key elements relevant to proteomics research.\n",
        "- **Standardise metadata** using ontologies (e.g., PSI-MS) to ensure consistency.\n",
        "- **Enable aggregation** of metadata across multiple datasets for broader analysis.\n",
        "\n",
        "This notebook is designed to help you extract and standardize metadata from the PRIDE (Proteomics Identifications Database) repository. Here’s what it does step by step:\n",
        "\n",
        "1. **Install Required Packages**  \n",
        "   - The notebook installs two key Python packages:\n",
        "     - **`owlready2`**: Used for loading and working with ontologies. An ontology is a controlled vocabulary that helps standardize terms (like instrument names) used in proteomics research.\n",
        "     - **`requests`**: Allows the notebook to make HTTP requests to the PRIDE API to fetch metadata.\n",
        "\n",
        "2. **Introduction and Project Goals**  \n",
        "   - At the very beginning, there is a detailed explanation (in markdown) about the project’s purpose. This includes:\n",
        "     - Extracting metadata for specific PRIDE datasets.\n",
        "     - Storing the metadata in JSON format.\n",
        "     - Mapping metadata fields to standardized ontology terms (using the PSI-MS ontology).\n",
        "     - Preparing the data for later aggregation and analysis.\n",
        "\n",
        "3. **Installing Additional Tools**  \n",
        "   - It also installs the `pridepy` package along with `tqdm` for enhanced progress tracking when working with PRIDE data. (Although this notebook focuses on metadata extraction, `pridepy` is useful for other parts of the project.)\n",
        "\n",
        "4. **Mounting Google Drive and Authentication**  \n",
        "   - The notebook mounts your Google Drive. This is done so that the extracted metadata files can be saved in a structured directory on your Drive.\n",
        "   - It then authenticates the user so that the notebook can access your Google Drive and any required Google services.\n",
        "\n",
        "5. **Loading and Exploring the PSI-MS Ontology**  \n",
        "   - The notebook loads the **PSI-MS ontology** from an online source. This ontology provides standardized terms for mass spectrometry and proteomics.\n",
        "   - It demonstrates a few examples:\n",
        "     - **Searching for specific terms:** For example, it searches for the term corresponding to an \"Orbitrap\" instrument and prints its label.\n",
        "     - **Finding related terms:** It shows how to search for terms containing “mass spectrometer” and checks hierarchical relationships (like whether one term is a child of another).\n",
        "     - **Iterating over ontology classes:** It prints all the classes (or categories) available in the ontology. This helps illustrate how metadata fields might be mapped to standardized terms.\n",
        "\n",
        "6. **Setting Module Parameters and Preparing Directories**  \n",
        "   - The notebook defines some key parameters:\n",
        "     - A **folder name** (e.g., “Hominins”) which will be used to organize the data.\n",
        "     - A **base directory path** on Google Drive where the experiment’s data will be stored.\n",
        "   - It then creates an “experiment” folder in the specified directory to hold all the metadata files.\n",
        "\n",
        "7. **Defining PRIDE Dataset IDs**  \n",
        "   - A list of PRIDE dataset IDs is defined (for example, “PXD003190”, “PXD003208”, etc.). These IDs represent the specific experiments or datasets that will be queried from the PRIDE repository.\n",
        "\n",
        "8. **Fetching Metadata from the PRIDE API**  \n",
        "   - A Python function called `fetch_pride_metadata` is defined:\n",
        "     - It takes a dataset ID and constructs the appropriate URL for the PRIDE API.\n",
        "     - It then sends a request to that URL. If the request is successful, the API returns metadata in JSON format.\n",
        "   - The notebook iterates over the list of PRIDE IDs, uses this function to fetch metadata for each, and saves each JSON response to a file. Each file is named after its corresponding PRIDE ID and stored in the experiment folder.\n",
        "\n",
        "9. **Saving and Confirming the Extracted Metadata**  \n",
        "   - After successfully fetching the metadata, the notebook writes the JSON data into separate files within the designated folder on Google Drive.\n",
        "   - It prints messages to the console confirming that the metadata for each PRIDE dataset has been successfully saved."
      ],
      "metadata": {
        "id": "I37u47QXcJog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "yYgNmCNmcYqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make Selections"
      ],
      "metadata": {
        "id": "z7RbsJTscdKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from google.colab import drive, auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from typing import Optional, List, Dict, Any\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LF91UlFSjZZi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Initial Setup and Drive Mounting\n",
        "# Mount Google Drive\n",
        "mount_point = '/content/drive'\n",
        "\n",
        "# Check if the drive is already mounted\n",
        "if os.path.exists(mount_point) and os.path.isdir(mount_point):\n",
        "    try:\n",
        "        os.listdir(mount_point) #tests if the drive is accessible.\n",
        "        print(\"Warning: Google Drive is already mounted. Please do not remount.\")\n",
        "    except:\n",
        "        drive.mount(mount_point) #If the drive exists, but is not accessible, then it is mounted.\n",
        "else:\n",
        "    drive.mount(mount_point)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QmFm5FJndLH",
        "outputId": "c8ecf080-3e1a-4726-80dc-ab5935d4133f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Google Drive is already mounted. Please do not remount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Configuration and Class Definitions\n",
        "# --- Module Parameters ---\n",
        "shared_drive_base_dir_str = \"/content/drive/Shareddrives/ZooMS_Data/PRIDE\"  # @param {type:\"string\"}\n",
        "spreadsheet_id = '127K6zdl5y46DRqUwRr-V32nUDoceaddbhG9XyozJs-4'  # @param {type:\"string\"}\n",
        "sheet_name = 'Metadata'  # @param {type:\"string\"}\n",
        "folder_name = 'Hominins'  # @param {type:\"string\"}\n",
        "\n",
        "# Create base directory if it doesn't exist\n",
        "os.makedirs(shared_drive_base_dir_str, exist_ok=True)\n",
        "os.chdir(shared_drive_base_dir_str)\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "1sDkPuUvnhz7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate for Google Sheets access\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "rvKXm1PVjepl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Script"
      ],
      "metadata": {
        "id": "FMmpOms-chw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Log Progress\n",
        "class ProgressLogger:\n",
        "    \"\"\"Helper class to manage progress reporting and logging\"\"\"\n",
        "\n",
        "    def __init__(self, name: str):\n",
        "        self.logger = logging.getLogger(name)\n",
        "        self.start_time = None\n",
        "\n",
        "    def start_section(self, section_name: str):\n",
        "        \"\"\"Start a new section of processing\"\"\"\n",
        "        self.start_time = datetime.now()\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"Starting: {section_name}\")\n",
        "        print(\"=\"*50)\n",
        "        self.logger.info(f\"Starting {section_name}\")\n",
        "\n",
        "    def end_section(self, section_name: str):\n",
        "        \"\"\"End a section of processing\"\"\"\n",
        "        duration = datetime.now() - self.start_time\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "        print(f\"Completed: {section_name}\")\n",
        "        print(f\"Duration: {duration}\")\n",
        "        print(\"-\"*50 + \"\\n\")\n",
        "        self.logger.info(f\"Completed {section_name}. Duration: {duration}\")\n",
        "\n",
        "    def log_progress(self, message: str, level: str = \"info\"):\n",
        "        \"\"\"Log a progress message\"\"\"\n",
        "        print(message)\n",
        "        getattr(self.logger, level)(message)\n",
        "\n",
        "def get_pride_ids_from_sheet(spreadsheet_id: str, sheet_name: str) -> List[str]:\n",
        "    \"\"\"Enhanced function to retrieve PRIDE IDs with progress reporting\"\"\"\n",
        "    progress = ProgressLogger(\"SheetReader\")\n",
        "    progress.start_section(\"Reading PRIDE IDs from Google Sheet\")\n",
        "\n",
        "    try:\n",
        "        service = build('sheets', 'v4')\n",
        "        sheet = service.spreadsheets()\n",
        "        range_name = f\"{sheet_name}!A2:A\"\n",
        "\n",
        "        progress.log_progress(f\"Accessing sheet: {sheet_name}\")\n",
        "        result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range_name).execute()\n",
        "        values = result.get('values', [])\n",
        "\n",
        "        if not values:\n",
        "            progress.log_progress(\"✗ No data found in sheet\", \"warning\")\n",
        "            return []\n",
        "\n",
        "        pride_ids = [row[0].strip() for row in values if row and row[0].strip().startswith('PXD')]\n",
        "\n",
        "        progress.log_progress(f\"✓ Found {len(pride_ids)} PRIDE IDs:\")\n",
        "        for px_id in pride_ids:\n",
        "            progress.log_progress(f\"  - {px_id}\")\n",
        "\n",
        "        progress.end_section(\"Reading PRIDE IDs\")\n",
        "        return pride_ids\n",
        "\n",
        "    except HttpError as err:\n",
        "        progress.log_progress(f\"✗ Failed to access sheet: {err}\", \"error\")\n",
        "        return []\n",
        "\n",
        "def fetch_pride_metadata(px_id: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Fetch metadata for a PRIDE project\"\"\"\n",
        "    base_url = \"https://www.ebi.ac.uk/pride/ws/archive/v3/projects\"\n",
        "    url = f\"{base_url}/{px_id}\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        metadata = response.json()\n",
        "        if not metadata:\n",
        "            return None\n",
        "\n",
        "        return metadata\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        if isinstance(e, requests.exceptions.HTTPError) and e.response.status_code == 404:\n",
        "            print(f\"✗ Project {px_id} not found (404)\")\n",
        "        else:\n",
        "            print(f\"✗ Error fetching {px_id}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"✗ Error parsing JSON response for {px_id}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def check_existing_metadata(px_id: str, output_dir: Path) -> bool:\n",
        "    \"\"\"Check if metadata file already exists for given PRIDE ID\"\"\"\n",
        "    metadata_file = output_dir / px_id / f\"{px_id}_experiment_metadata.json\"\n",
        "    return metadata_file.exists()\n",
        "\n",
        "\n",
        "def save_metadata(metadata: Dict[str, Any], px_id: str, output_dir: Path, mapped: bool = False) -> bool:\n",
        "    \"\"\"\n",
        "    Save experiment-level metadata only if it doesn't already exist.\n",
        "\n",
        "    The file is saved in a subfolder named after the PRIDE ID, e.g.:\n",
        "      <output_dir>/<px_id>/<px_id>_experiment_metadata.json\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure that output_dir is the folder where experiment subfolders reside (e.g., \"Hominins\")\n",
        "        # Create a subdirectory for this project if it doesn't exist.\n",
        "        project_dir = output_dir / px_id\n",
        "        project_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Define the output file name inside the project subfolder.\n",
        "        output_file = project_dir / f\"{px_id}_experiment_metadata.json\"\n",
        "        logger.info(f\"Computed output file path: {output_file}\")\n",
        "\n",
        "        # Check if the file already exists in the project subfolder.\n",
        "        if output_file.exists():\n",
        "            logger.info(f\"Experiment metadata file already exists for {px_id} at {output_file}\")\n",
        "            return True  # File already exists, so do nothing.\n",
        "\n",
        "        # Write the metadata into the file within the project subfolder.\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
        "        logger.info(f\"Experiment metadata saved successfully for {px_id} in {project_dir}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving metadata for {px_id}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def main(spreadsheet_id: str, sheet_name: str, base_dir: str, folder_name: str):\n",
        "    \"\"\"Main execution function with file organization and existence checks\"\"\"\n",
        "    progress = ProgressLogger(\"Main\")\n",
        "\n",
        "    # Setup and initialization\n",
        "    progress.start_section(\"Initialization\")\n",
        "    output_dir = Path(base_dir) / folder_name\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    progress.log_progress(f\"Output directory: {output_dir}\")\n",
        "\n",
        "    # Get PRIDE IDs\n",
        "    pride_ids = get_pride_ids_from_sheet(spreadsheet_id, sheet_name)\n",
        "    if not pride_ids:\n",
        "        progress.log_progress(\"✗ No valid PRIDE IDs found. Exiting.\", \"error\")\n",
        "        return\n",
        "\n",
        "    # Process each PRIDE ID\n",
        "    progress.start_section(\"Processing PRIDE Projects\")\n",
        "    stats = {\n",
        "        \"total\": len(pride_ids),\n",
        "        \"skipped\": 0,\n",
        "        \"successful\": 0,\n",
        "        \"failed\": 0\n",
        "    }\n",
        "\n",
        "    for px_id in tqdm(pride_ids, desc=\"Processing projects\"):\n",
        "        progress.log_progress(f\"\\nChecking {px_id}\")\n",
        "\n",
        "        # Check if metadata already exists\n",
        "        if check_existing_metadata(px_id, output_dir):\n",
        "            progress.log_progress(f\"⏭ Skipping {px_id} - metadata already exists\")\n",
        "            stats[\"skipped\"] += 1\n",
        "            continue\n",
        "\n",
        "        # Fetch metadata\n",
        "        progress.log_progress(f\"Fetching metadata for {px_id}\")\n",
        "        metadata = fetch_pride_metadata(px_id)\n",
        "\n",
        "        if metadata:\n",
        "            # Save metadata\n",
        "            if save_metadata(metadata, px_id, output_dir):\n",
        "                progress.log_progress(f\"✓ Successfully processed {px_id}\")\n",
        "                stats[\"successful\"] += 1\n",
        "            else:\n",
        "                progress.log_progress(f\"✗ Failed to save metadata for {px_id}\")\n",
        "                stats[\"failed\"] += 1\n",
        "        else:\n",
        "            progress.log_progress(f\"✗ Failed to fetch metadata for {px_id}\")\n",
        "            stats[\"failed\"] += 1\n",
        "\n",
        "    # Final summary\n",
        "    progress.start_section(\"Final Summary\")\n",
        "    progress.log_progress(f\"\"\"\n",
        "Processing Complete:\n",
        "- Total projects: {stats['total']}\n",
        "- Already existed (skipped): {stats['skipped']}\n",
        "- Successfully processed: {stats['successful']}\n",
        "- Failed: {stats['failed']}\n",
        "\"\"\")\n",
        "    progress.end_section(\"Process Complete\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nNwGpyJtyw7D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "    # Mount Google Drive if needed\n",
        "    if not os.path.ismount('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    # Authenticate for Google Sheets access\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    # Run main processing\n",
        "    main(\n",
        "    spreadsheet_id=spreadsheet_id,\n",
        "    sheet_name=sheet_name,\n",
        "    base_dir=shared_drive_base_dir_str,\n",
        "    folder_name=folder_name\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuB0qHXUzpWz",
        "outputId": "31598ff9-9170-4a20-b66a-2224671be47f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Starting: Initialization\n",
            "==================================================\n",
            "Output directory: /content/drive/Shareddrives/ZooMS_Data/PRIDE/Hominins\n",
            "\n",
            "==================================================\n",
            "Starting: Reading PRIDE IDs from Google Sheet\n",
            "==================================================\n",
            "Accessing sheet: Metadata\n",
            "✓ Found 8 PRIDE IDs:\n",
            "  - PXD011377\n",
            "  - PXD018264\n",
            "  - PXD018721\n",
            "  - PXD020530\n",
            "  - PXD043272\n",
            "  - PXD045412\n",
            "  - PXD047932\n",
            "  - PXD058447\n",
            "\n",
            "--------------------------------------------------\n",
            "Completed: Reading PRIDE IDs\n",
            "Duration: 0:00:06.036005\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "==================================================\n",
            "Starting: Processing PRIDE Projects\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing projects: 100%|██████████| 8/8 [00:00<00:00, 69.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking PXD011377\n",
            "⏭ Skipping PXD011377 - metadata already exists\n",
            "\n",
            "Checking PXD018264\n",
            "⏭ Skipping PXD018264 - metadata already exists\n",
            "\n",
            "Checking PXD018721\n",
            "⏭ Skipping PXD018721 - metadata already exists\n",
            "\n",
            "Checking PXD020530\n",
            "⏭ Skipping PXD020530 - metadata already exists\n",
            "\n",
            "Checking PXD043272\n",
            "⏭ Skipping PXD043272 - metadata already exists\n",
            "\n",
            "Checking PXD045412\n",
            "⏭ Skipping PXD045412 - metadata already exists\n",
            "\n",
            "Checking PXD047932\n",
            "⏭ Skipping PXD047932 - metadata already exists\n",
            "\n",
            "Checking PXD058447\n",
            "Fetching metadata for PXD058447\n",
            "✗ Project PXD058447 not found (404)\n",
            "✗ Failed to fetch metadata for PXD058447\n",
            "\n",
            "==================================================\n",
            "Starting: Final Summary\n",
            "==================================================\n",
            "\n",
            "Processing Complete:\n",
            "- Total projects: 8\n",
            "- Already existed (skipped): 7\n",
            "- Successfully processed: 0\n",
            "- Failed: 1\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Completed: Process Complete\n",
            "Duration: 0:00:00.000040\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}